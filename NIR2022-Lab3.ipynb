{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NIR 2022 - Lab 3: Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Lab 2, we have seen how to index a collection of documents and how to search the index with different systems in PyTerrier.\n",
    "At the end of Lab 2, we also saw how to evaluate the performance of the different systems using standard metrics such as MAP and NDCG.\n",
    "\n",
    "Today, we will take a closer look at standard evaluation metrics.\n",
    "In particular, we will see how to use `pytrec_eval`, a Python library to evaluate on TREC-like data whether you use PyTerrier or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Systems Setup\n",
    "\n",
    "We will start by building an index of our data collection and a few systems in PyTerrier.\n",
    "This step is only required to obtain system outputs.\n",
    "\n",
    "As we will see shortly, `pytrec_eval` only needs access to output files, which can be obtained in any other way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2453, 2)\n",
      "     docno                                               text\n",
      "0   935016  he emigrated to france with his family in 1956...\n",
      "1  2360440  after being ambushed by the germans in novembe...\n",
      "2   347765  she was the second ship named for captain alex...\n",
      "3  1969335  world war ii was a global war that was under w...\n",
      "4  1576938  the ship was ordered on 2 april 1942 laid down...\n",
      "(9, 2)\n",
      "       qid                 query\n",
      "0  1015979    president of chile\n",
      "1     2674    computer animation\n",
      "2   340095  2020 summer olympics\n",
      "3  1502917         train station\n",
      "4     2574       chinese cuisine\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "import pandas as pd\n",
    "\n",
    "# corpus\n",
    "docs_df = pd.read_csv('data/lab_docs.csv', dtype=str)\n",
    "print(docs_df.shape)\n",
    "print(docs_df.head())\n",
    "\n",
    "# topics\n",
    "topics_df = pd.read_csv('data/lab_topics.csv', dtype=str)\n",
    "print(topics_df.shape)\n",
    "print(topics_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTerrier 0.8.1 has loaded Terrier 5.6 (built by craigmacdonald on 2021-09-17 13:27)\n",
      "\n",
      "No etc/terrier.properties, using terrier.default.properties for bootstrap configuration.\n"
     ]
    }
   ],
   "source": [
    "# Init PyTerrier\n",
    "import pyterrier as pt\n",
    "if not pt.started():\n",
    "    pt.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 2453\n",
      "Number of terms: 23693\n",
      "Number of postings: 208487\n",
      "Number of fields: 0\n",
      "Number of tokens: 273373\n",
      "Field names: []\n",
      "Positions:   true\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Build index\n",
    "indexer = pt.DFIndexer(\"./indexes/default\", overwrite=True, blocks=True)\n",
    "index_ref = indexer.index(docs_df[\"text\"], docs_df[\"docno\"])\n",
    "index = pt.IndexFactory.of(index_ref)\n",
    "print(index.getCollectionStatistics().toString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build IR systems\n",
    "tf = pt.BatchRetrieve(index, wmodel=\"Tf\")\n",
    "tfidf = pt.BatchRetrieve(index, wmodel=\"TF_IDF\")\n",
    "bm25 = pt.BatchRetrieve(index, wmodel=\"BM25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search and Evaluate in PyTerrier\n",
    "\n",
    "In PyTerrier, we can use `search()` to search for documents relevant for a given query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docid</th>\n",
       "      <th>docno</th>\n",
       "      <th>rank</th>\n",
       "      <th>score</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1357</td>\n",
       "      <td>1221197</td>\n",
       "      <td>0</td>\n",
       "      <td>8.052834</td>\n",
       "      <td>black wall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>203</td>\n",
       "      <td>1455841</td>\n",
       "      <td>1</td>\n",
       "      <td>6.727179</td>\n",
       "      <td>black wall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1172</td>\n",
       "      <td>679402</td>\n",
       "      <td>2</td>\n",
       "      <td>6.412557</td>\n",
       "      <td>black wall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2110</td>\n",
       "      <td>2391064</td>\n",
       "      <td>3</td>\n",
       "      <td>5.677738</td>\n",
       "      <td>black wall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1452</td>\n",
       "      <td>702865</td>\n",
       "      <td>4</td>\n",
       "      <td>5.161479</td>\n",
       "      <td>black wall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1845</td>\n",
       "      <td>1151865</td>\n",
       "      <td>5</td>\n",
       "      <td>4.991523</td>\n",
       "      <td>black wall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>293</td>\n",
       "      <td>243238</td>\n",
       "      <td>6</td>\n",
       "      <td>4.941458</td>\n",
       "      <td>black wall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2028</td>\n",
       "      <td>163616</td>\n",
       "      <td>7</td>\n",
       "      <td>4.894899</td>\n",
       "      <td>black wall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>592</td>\n",
       "      <td>692168</td>\n",
       "      <td>8</td>\n",
       "      <td>4.808818</td>\n",
       "      <td>black wall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1335</td>\n",
       "      <td>1872141</td>\n",
       "      <td>9</td>\n",
       "      <td>4.593691</td>\n",
       "      <td>black wall</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  qid  docid    docno  rank     score       query\n",
       "0   1   1357  1221197     0  8.052834  black wall\n",
       "1   1    203  1455841     1  6.727179  black wall\n",
       "2   1   1172   679402     2  6.412557  black wall\n",
       "3   1   2110  2391064     3  5.677738  black wall\n",
       "4   1   1452   702865     4  5.161479  black wall\n",
       "5   1   1845  1151865     5  4.991523  black wall\n",
       "6   1    293   243238     6  4.941458  black wall\n",
       "7   1   2028   163616     7  4.894899  black wall\n",
       "8   1    592   692168     8  4.808818  black wall\n",
       "9   1   1335  1872141     9  4.593691  black wall"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Search the index for a query using TF-IDF model\n",
    "tfidf.search(\"black wall\").head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also search for multiple queries at once by grouping them in a Pandas DataFrame and then using the `transform()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docid</th>\n",
       "      <th>docno</th>\n",
       "      <th>rank</th>\n",
       "      <th>score</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>q1</td>\n",
       "      <td>759</td>\n",
       "      <td>1782559</td>\n",
       "      <td>0</td>\n",
       "      <td>7.858059</td>\n",
       "      <td>dragon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>q1</td>\n",
       "      <td>201</td>\n",
       "      <td>1076935</td>\n",
       "      <td>1</td>\n",
       "      <td>4.848641</td>\n",
       "      <td>dragon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>q1</td>\n",
       "      <td>2194</td>\n",
       "      <td>654718</td>\n",
       "      <td>2</td>\n",
       "      <td>4.689944</td>\n",
       "      <td>dragon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>q1</td>\n",
       "      <td>1383</td>\n",
       "      <td>1323966</td>\n",
       "      <td>3</td>\n",
       "      <td>4.656079</td>\n",
       "      <td>dragon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>q1</td>\n",
       "      <td>1576</td>\n",
       "      <td>630588</td>\n",
       "      <td>4</td>\n",
       "      <td>4.639329</td>\n",
       "      <td>dragon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>q1</td>\n",
       "      <td>26</td>\n",
       "      <td>1610206</td>\n",
       "      <td>5</td>\n",
       "      <td>4.573517</td>\n",
       "      <td>dragon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>q2</td>\n",
       "      <td>1172</td>\n",
       "      <td>679402</td>\n",
       "      <td>0</td>\n",
       "      <td>6.412557</td>\n",
       "      <td>wall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>q2</td>\n",
       "      <td>2110</td>\n",
       "      <td>2391064</td>\n",
       "      <td>1</td>\n",
       "      <td>5.677738</td>\n",
       "      <td>wall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>q2</td>\n",
       "      <td>1452</td>\n",
       "      <td>702865</td>\n",
       "      <td>2</td>\n",
       "      <td>5.161479</td>\n",
       "      <td>wall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>q2</td>\n",
       "      <td>1357</td>\n",
       "      <td>1221197</td>\n",
       "      <td>3</td>\n",
       "      <td>5.055549</td>\n",
       "      <td>wall</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  qid  docid    docno  rank     score   query\n",
       "0  q1    759  1782559     0  7.858059  dragon\n",
       "1  q1    201  1076935     1  4.848641  dragon\n",
       "2  q1   2194   654718     2  4.689944  dragon\n",
       "3  q1   1383  1323966     3  4.656079  dragon\n",
       "4  q1   1576   630588     4  4.639329  dragon\n",
       "5  q1     26  1610206     5  4.573517  dragon\n",
       "6  q2   1172   679402     0  6.412557    wall\n",
       "7  q2   2110  2391064     1  5.677738    wall\n",
       "8  q2   1452   702865     2  5.161479    wall\n",
       "9  q2   1357  1221197     3  5.055549    wall"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Search the index for multiple queries using TF-IDF model\n",
    "queries = pd.DataFrame([[\"q1\", \"dragon\"], [\"q2\", \"wall\"]], columns=[\"qid\", \"query\"])\n",
    "tfidf.transform(queries).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, PyTerrier provides an interface for evaluating the performance of IR systems through the `Experiment` abstraction.\n",
    "Behind the scenes, `pt.Experiment` uses the `pytrec_eval` library!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docno</th>\n",
       "      <th>label</th>\n",
       "      <th>iteration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1015979</td>\n",
       "      <td>1015979</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1015979</td>\n",
       "      <td>2226456</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1015979</td>\n",
       "      <td>1514612</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1015979</td>\n",
       "      <td>1119171</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1015979</td>\n",
       "      <td>1053174</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       qid    docno label iteration\n",
       "0  1015979  1015979     2         0\n",
       "1  1015979  2226456     1         0\n",
       "2  1015979  1514612     1         0\n",
       "3  1015979  1119171     1         0\n",
       "4  1015979  1053174     1         0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qrels_df = pd.read_csv('data/lab_qrels.csv', dtype=str)\n",
    "qrels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1015979</td>\n",
       "      <td>president of chile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2674</td>\n",
       "      <td>computer animation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>340095</td>\n",
       "      <td>2020 summer olympics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1502917</td>\n",
       "      <td>train station</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2574</td>\n",
       "      <td>chinese cuisine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       qid                 query\n",
       "0  1015979    president of chile\n",
       "1     2674    computer animation\n",
       "2   340095  2020 summer olympics\n",
       "3  1502917         train station\n",
       "4     2574       chinese cuisine"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>map</th>\n",
       "      <th>ndcg</th>\n",
       "      <th>ndcg_cut_10</th>\n",
       "      <th>P_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TF</td>\n",
       "      <td>0.727657</td>\n",
       "      <td>0.879601</td>\n",
       "      <td>0.943447</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.777422</td>\n",
       "      <td>0.881052</td>\n",
       "      <td>0.933542</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BM25</td>\n",
       "      <td>0.777422</td>\n",
       "      <td>0.881052</td>\n",
       "      <td>0.933542</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name       map      ndcg  ndcg_cut_10      P_10\n",
       "0      TF  0.727657  0.879601     0.943447  0.833333\n",
       "1  TF-IDF  0.777422  0.881052     0.933542  0.833333\n",
       "2    BM25  0.777422  0.881052     0.933542  0.833333"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate systems on the first three topics using the PyTerrier Experiment interface\n",
    "qrels_df = qrels_df.astype({'label': 'int32'})\n",
    "pt.Experiment(\n",
    "    retr_systems=[tf, tfidf, bm25],\n",
    "    names=['TF', 'TF-IDF', 'BM25'],\n",
    "    topics=topics_df[:3],\n",
    "    qrels=qrels_df,\n",
    "    eval_metrics=[\"map\", \"ndcg\", \"ndcg_cut_10\", \"P_10\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformers & Operators\n",
    "\n",
    "You'll have noted that BatchRetrieve has a `transform()` method that takes as input a dataframe, and returns another dataframe, which is somehow a *transformation* of the earlier dataframe (e.g., a retrieval transformation). In fact, `BatchRetrieve` is just one of many similar objects in PyTerrier, which we call [transformers](https://pyterrier.readthedocs.io/en/latest/transformer.html) (represented by the `TransformerBase` class).\n",
    "\n",
    "Let's give a look at a `BatchRetrieve` transformer, starting with one for the TF_IDF weighting model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# check tfidf is a transformer...\n",
    "print(isinstance(tfidf, pt.transformer.TransformerBase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(pyterrier.batchretrieve.BatchRetrieve,\n",
       " pyterrier.batchretrieve.BatchRetrieveBase,\n",
       " pyterrier.transformer.TransformerBase,\n",
       " pyterrier.transformer.Transformer,\n",
       " matchpy.expressions.expressions.Symbol,\n",
       " matchpy.expressions.expressions.Atom,\n",
       " matchpy.expressions.expressions.Expression,\n",
       " object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this prints the type hierarchy of the TF_IDF class\n",
    "tfidf.__class__.__mro__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The interesting capability of all transformers is that they can be combined using Python operators (this is called operator overloading).\n",
    "\n",
    "Concretely, imagine that you want to chain transformers together – e.g. rank documents first by Tf then re-ranked the exact same documents by TF_IDF. We can do this using the >> operator – we call this composition, or \"then\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# now let's define a pipeline \n",
    "pipeline = tf >> tfidf\n",
    "print(isinstance(tfidf, pt.transformer.TransformerBase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   qid  docid    docno  rank  score       query\n",
      "0    1   1172   679402     0    5.0  black wall\n",
      "1    1   2028   163616     1    4.0  black wall\n",
      "2    1   1335  1872141     2    3.0  black wall\n",
      "3    1   1357  1221197     3    3.0  black wall\n",
      "4    1   2110  2391064     4    3.0  black wall\n",
      "..  ..    ...      ...   ...    ...         ...\n",
      "79   1   2166   430722    79    1.0  black wall\n",
      "80   1   2290    86366    80    1.0  black wall\n",
      "81   1   2305   993780    81    1.0  black wall\n",
      "82   1   2337   427183    82    1.0  black wall\n",
      "83   1   2414  2177292    83    1.0  black wall\n",
      "\n",
      "[84 rows x 6 columns]\n",
      "   qid  docid    docno  rank     score       query\n",
      "0    1   1357  1221197     0  8.052834  black wall\n",
      "1    1    203  1455841     1  6.727179  black wall\n",
      "2    1   1172   679402     2  6.412557  black wall\n",
      "3    1   2110  2391064     3  5.677738  black wall\n",
      "4    1   1452   702865     4  5.161479  black wall\n",
      "..  ..    ...      ...   ...       ...         ...\n",
      "79   1   1142   659277    79  2.787666  black wall\n",
      "80   1    216  1791381    80  2.777952  black wall\n",
      "81   1   2305   993780    81  2.758726  black wall\n",
      "82   1   1241  1485477    82  2.749212  black wall\n",
      "83   1    699  1047828    83  2.711805  black wall\n",
      "\n",
      "[84 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(tf.search(\"black wall\"))\n",
    "print(pipeline.search(\"black wall\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Task – Pipeline Construction\n",
    "\n",
    "Create a ranker that performs the follinwg:\n",
    " - obtains the top 10 highest scoring documents by term frequency (`wmodel=\"Tf\"`)\n",
    " - obtains the top 10 highest scoring documents by TF.IDF (`wmodel=\"TF_IDF\"`)\n",
    " - reranks only those documents found in BOTH of the previous retrieval settings using BM25.\n",
    "\n",
    "How many documents are retrieved by this full pipeline for the query `\"black wall\"`. \n",
    "\n",
    "If you obtain the correct solution, the document with docid `'1357'` should have a score 14.5976"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving system ouputs\n",
    "\n",
    "We now save the output of each query onto disk so we can later evaluate it with `pytrec_eval`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1015979</td>\n",
       "      <td>president of chile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2674</td>\n",
       "      <td>computer animation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>340095</td>\n",
       "      <td>2020 summer olympics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1502917</td>\n",
       "      <td>train station</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2574</td>\n",
       "      <td>chinese cuisine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14082</td>\n",
       "      <td>world war ii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1250390</td>\n",
       "      <td>painting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5597</td>\n",
       "      <td>house</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8438</td>\n",
       "      <td>mexican cuisine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       qid                 query\n",
       "0  1015979    president of chile\n",
       "1     2674    computer animation\n",
       "2   340095  2020 summer olympics\n",
       "3  1502917         train station\n",
       "4     2574       chinese cuisine\n",
       "5    14082          world war ii\n",
       "6  1250390              painting\n",
       "7     5597                 house\n",
       "8     8438       mexican cuisine"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘outputs’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1015979 0 1015979 0 20.927815031462014 tfidf'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save system rankings in TREC format\n",
    "# qid Q0 docno rank score tag\n",
    "tf_run = []\n",
    "for _, row in topics_df.iterrows():\n",
    "    qid, query = row\n",
    "    res_df = tf.search(query)\n",
    "    for _, res_row in res_df.iterrows():\n",
    "        _, docid, docno, rank, score, query = res_row\n",
    "        row_str = f\"{qid} 0 {docno} {rank} {score} tfidf\"\n",
    "        tf_run.append(row_str)\n",
    "with open(\"outputs/tf.run\", \"w\") as f:\n",
    "    for l in tf_run:\n",
    "        f.write(l + \"\\n\")\n",
    "        \n",
    "tfidf_run = []\n",
    "for _, row in topics_df.iterrows():\n",
    "    qid, query = row\n",
    "    res_df = tfidf.search(query)\n",
    "    for _, res_row in res_df.iterrows():\n",
    "        _, docid, docno, rank, score, query = res_row\n",
    "        row_str = f\"{qid} 0 {docno} {rank} {score} tfidf\"\n",
    "        tfidf_run.append(row_str)\n",
    "with open(\"outputs/tfidf.run\", \"w\") as f:\n",
    "    for l in tfidf_run:\n",
    "        f.write(l + \"\\n\")\n",
    "\n",
    "bm25_run = []\n",
    "for _, row in topics_df.iterrows():\n",
    "    qid, query = row\n",
    "    res_df = bm25.search(query)\n",
    "    for _, res_row in res_df.iterrows():\n",
    "        _, docid, docno, rank, score, query = res_row\n",
    "        row_str = f\"{qid} 0 {docno} {rank} {score} tfidf\"\n",
    "        bm25_run.append(row_str)\n",
    "with open(\"outputs/bm25.run\", \"w\") as f:\n",
    "    for l in bm25_run:\n",
    "        f.write(l + \"\\n\")\n",
    "\n",
    "bm25_run[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pytrec_eval\n",
    "\n",
    "[pytrec_eval](https://github.com/cvangysel/pytrec_eval) is a Python interface to TREC's evaluation tool [`trec_eval`](https://github.com/usnistgov/trec_eval).\n",
    "You can install it as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/maps/projects/futhark1/data/wzm289/miniconda3/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/maps/projects/futhark1/data/wzm289/miniconda3/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: pytrec_eval in /maps/projects/futhark1/data/wzm289/miniconda3/lib/python3.9/site-packages (0.5)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/maps/projects/futhark1/data/wzm289/miniconda3/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/maps/projects/futhark1/data/wzm289/miniconda3/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/maps/projects/futhark1/data/wzm289/miniconda3/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/maps/projects/futhark1/data/wzm289/miniconda3/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/home/wzm289/miniconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pytrec_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pytrec_eval requires three arguments:\n",
    "- qrel: a dictionary mapping each query id to the relevant documents and their labels. For example:\n",
    "```python\n",
    "qrel = {\n",
    "    'q1': {'d1': 0, 'd2': 1, 'd3': 0},\n",
    "    'q2': {'d2': 1, 'd3': 1},\n",
    "}\n",
    "```\n",
    "- metrics: a set of standard metrics to be used to assess your system. See [here](http://www.rafaelglater.com/en/post/learn-how-to-use-trec_eval-to-evaluate-your-information-retrieval-system) for a list of available metrics.\n",
    "- run: similar to `qrel`, this is a dictionary of a given run which maps each query id to the relevant documents and their scores. For example:\n",
    "```python\n",
    "run = {\n",
    "    'q1': {'d1': 1.0, 'd2': 0.0, 'd3': 1.5},\n",
    "    'q2': {'d1': 1.5, 'd2': 0.2, 'd3': 0.5}\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2454, 4)\n",
      "       qid    docno label iteration\n",
      "0  1015979  1015979     2         0\n",
      "1  1015979  2226456     1         0\n",
      "2  1015979  1514612     1         0\n",
      "3  1015979  1119171     1         0\n",
      "4  1015979  1053174     1         0\n"
     ]
    }
   ],
   "source": [
    "# Load qrels\n",
    "qrels_df = pd.read_csv('data/lab_qrels.csv', dtype=str)\n",
    "print(qrels_df.shape)\n",
    "print(qrels_df.head())\n",
    "\n",
    "qrels_dict = dict()\n",
    "for _, r in qrels_df.iterrows():\n",
    "    qid, docno, label, iteration = r\n",
    "    if qid not in qrels_dict:\n",
    "        qrels_dict[qid] = dict()\n",
    "    qrels_dict[qid][docno] = int(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out `pytrec_eval.parse_qrel()` to quickly load qrels files in TREC format (as in your project)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytrec_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build evaluator based on the qrels and metrics\n",
    "metrics = {\"map\", \"ndcg\", \"ndcg_cut_10\", \"P_10\"}\n",
    "my_qrel = {q: d for q, d in qrels_dict.items() if q in {'1015979', '2674', '340095'}}  # let's evaluate the first 3 topics to compare with PyTerrier above\n",
    "evaluator = pytrec_eval.RelevanceEvaluator(my_qrel, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load run\n",
    "with open(\"outputs/tf.run\", 'r') as f_run:\n",
    "    tf_run = pytrec_eval.parse_run(f_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1015979': {'map': 0.6884429327286471,\n",
       "  'P_10': 0.5,\n",
       "  'ndcg': 0.9080664916757495,\n",
       "  'ndcg_cut_10': 0.830339843386306},\n",
       " '2674': {'map': 0.5050126570739595,\n",
       "  'P_10': 1.0,\n",
       "  'ndcg': 0.7326486367413882,\n",
       "  'ndcg_cut_10': 1.0},\n",
       " '340095': {'map': 0.9895163758800121,\n",
       "  'P_10': 1.0,\n",
       "  'ndcg': 0.9980874339288609,\n",
       "  'ndcg_cut_10': 1.0}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate tf model\n",
    "tf_evals = evaluator.evaluate(tf_run)\n",
    "tf_evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_metric2vals = {m: [] for m in metrics}\n",
    "for q, d in tf_evals.items():\n",
    "    for m, val in d.items():\n",
    "        tf_metric2vals[m].append(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10 \t 0.943446614462102\n",
      "map \t 0.7276573218942062\n",
      "P_10 \t 0.8333333333333334\n",
      "ndcg \t 0.879600854115333\n"
     ]
    }
   ],
   "source": [
    "# Compute average across topics\n",
    "for m in metrics:\n",
    "    print(m, '\\t', pytrec_eval.compute_aggregated_measure(m, tf_metric2vals[m]))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d8ed0073c41b023cdd22b6268c6b3f0c9b6d97a6234cf243afa672a36c79f6c6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
