{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NIR 2022 - Lab 2: Introduction to PyTerrier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0: Libraries for Indexing and Ranking\n",
    "\n",
    "There exist several software libraries that can help you develop a search engine.\n",
    "They usually provide highly optimized indexes, scoring algorithms (e.g. BM25) and other features such as text pre-processing.\n",
    "\n",
    "Popular libraries include:\n",
    "- [INDRI](https://www.lemurproject.org/indri/)\n",
    "- [Elasticsearch](https://github.com/elastic/elasticsearch)\n",
    "- [Anserini](https://github.com/castorini/anserini)\n",
    "- [Terrier](https://github.com/terrier-org/terrier-core)\n",
    "- [Whoosh](https://pypi.org/project/Whoosh/)\n",
    "\n",
    "As Python is becoming the standard programming language in Data Science and Deep Learning, Python interfaces have been added to several libraries:\n",
    "- [Elasticsearch-py](https://github.com/elastic/elasticsearch-py) for Elasticsearch\n",
    "- [Pyserini](https://github.com/castorini/pyserini/) for Anserini\n",
    "- [Py-Terrier](https://github.com/terrier-org/pyterrier) for Terrier\n",
    "- [BEIR](https://github.com/beir-cellar/beir.git) for BEIR\n",
    "\n",
    "The role of these Python interfaces is to understand your Python code and to map it onto the underlying service.\n",
    "For example, PyTerrier is a Python layer above Terrier:\n",
    "![PyTerrier](figures/PyTerrier.png \"PyTerrier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1: PyTerrier\n",
    "\n",
    "In our first labs, we will be using PyTerrier: a new Python Framework that makes it easy to perform information retrieval experiments in Python while using the Java-based Terrier platform for the expensive indexing and retrieval operations.\n",
    "\n",
    "In particular, the material of the lab is heavily based on the [ECIR 2021 tutorial](https://github.com/terrier-org/ecir2021tutorial) with PyTerrier and [OpenNIR](https://github.com/Georgetown-IR-Lab/OpenNIR) search toolkits.\n",
    "\n",
    "Another useful resource is the [PyTerrier documentation](https://pyterrier.readthedocs.io/_/downloads/en/latest/pdf/).\n",
    "\n",
    "NB. You can choose any library you prefer to develop your final project. \n",
    "Our labs aim to provide guidance into applying the theoretical content of the lectures in practice.\n",
    "As such, we only use one library and a small dataset during the lab sessions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "PyTerrier does not yet easily install on Windows.\n",
    "\n",
    "If you do not have a Linux or macOS device, one of the easiest options is to use <a href=\"https://colab.research.google.com/\">Google Colab</a>.\n",
    "\n",
    "Get in touch with the TA if you need help setting up Google Colab!\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2: Pre-requisites\n",
    "\n",
    "PyTerrier requires:\n",
    "- Python 3.6 or newer\n",
    "    + You can check your Python version by running `python --version` or `python3 --version` on the terminal\n",
    "    + You can download a newer version from [here](https://www.python.org/downloads/)\n",
    "    + Once you have a valid Python version installed, make sure your Jupyter notebook is using it (`Kernel -> Change Kernel`)\n",
    "- Java 11 or newer\n",
    "    + You can check your Java version by running `java --version` on the terminal\n",
    "    + You can download and install Java 11 from [JDK 11](https://www.oracle.com/java/technologies/javase-jdk11-downloads.html) or [OpenJDK 11](http://jdk.java.net/archive/). Several tutorials exist to help you in this task, such as [this one for Linux](https://computingforgeeks.com/how-to-install-java-11-on-ubuntu-debian-linux/) and [this one for macOS](https://mkyong.com/java/how-to-install-java-on-mac-osx/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3: Installation\n",
    "\n",
    "PyTerrier can be easily installed from the terminal using Pip:\n",
    "```bash\n",
    "pip install python-terrier\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install python-terrier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4: Configuration\n",
    "\n",
    "To use PyTerrier, we need to both import it and initialize it.\n",
    "The initialization with the `init()` method makes PyTerrier download Terrier's JAR file as well as start the Java virtual machine.\n",
    "To avoid `init()` being called more than once, we can check if it's being initialized through the `started()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyterrier as pt\n",
    "if not pt.started():\n",
    "    pt.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5: Data\n",
    "\n",
    "In our labs, we will be using a subset of the small version of [WikIR](https://www.aclweb.org/anthology/2020.lrec-1.237.pdf) dataset for English.\n",
    "\n",
    "The data is located inside the `data/` folder, and consists of:\n",
    "- `lab_docs.csv`: CSV file of document number and document text\n",
    "- `lab_topics.csv`: CSV file of query id and query text\n",
    "- `lab_qrels.csv`: CSV file of annotations with schema `qid, docno, label, iteration`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_df = pd.read_csv('data/lab_docs.csv', dtype=str)\n",
    "print(docs_df.shape)\n",
    "docs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_df = pd.read_csv('data/lab_topics.csv', dtype=str)\n",
    "print(topics_df.shape)\n",
    "topics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qrels_df = pd.read_csv('data/lab_qrels.csv', dtype=str)\n",
    "print(qrels_df.shape)\n",
    "qrels_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6: Indexing and Indexes\n",
    "\n",
    "To perform the task of retrieving relevant documents for a given query, a search engine needs to know which documents are available and index them to efficiently retrieve them.\n",
    "\n",
    "In PyTerrier, we can create an index from a Pandas DataFrame with the `DFIndexer` method.\n",
    "The index, with all its data structures, is written into a directory called `indexes/default`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = pt.DFIndexer(\"./indexes/default\", overwrite=True)\n",
    "index_ref = indexer.index(docs_df[\"text\"], docs_df[\"docno\"])\n",
    "index_ref.toString()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The returned `IndexRef` is basically a string saying where an index is stored.\n",
    "A PyTerrier index contains several files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lh indexes/default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These files represent several data structures:\n",
    "- Lexicon: Records the list of all unique terms and their statistics\n",
    "- Document index: Records the statistics of all documents (e.g. document length)\n",
    "- Inverted index: Records the mapping between terms and documents\n",
    "- Meta index: Records document metadata (e.g. document number, URL, raw text, etc passed through `indexer.index()`)\n",
    "- Direct index: Records terms for each document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have an `IndexRef`, we can load it to an actual index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pt.IndexFactory.of(index_ref)\n",
    "\n",
    "# lets see what type index is\n",
    "type(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so this object refers to Terrier's [`Index`](http://terrier.org/docs/current/javadoc/org/terrier/structures/Index.html) type. \n",
    "\n",
    "Looking at the linked Javadoc, we can see that this Java object has methods such as:\n",
    " - `getCollectionStatistics()`\n",
    " - `getInvertedIndex()`\n",
    " - `getLexicon()`\n",
    "\n",
    "Let's see what is returned by the `CollectionStatistics()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(index.getCollectionStatistics().toString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.getEnd()\n",
    "index.getStart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.getDocumentIndex().getDocumentLength(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.getMetaIndex().getAllItems(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lexicon\n",
    "\n",
    "What is our vocabulary of terms?\n",
    "\n",
    "This is the [Lexicon](http://terrier.org/docs/current/javadoc/org/terrier/structures/Lexicon.html), which can be iterated easily from Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix_range = range(1900, 1905)\n",
    "for ix, kv in enumerate(index.getLexicon()):\n",
    "    if ix in ix_range:\n",
    "        print(f\"{kv.getKey()} -> {kv.getValue().toString()}\")\n",
    "    elif ix > ix_range[-1]:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, iterating over the Lexicon returns a pair of String term and a [LexiconEntry](http://terrier.org/docs/current/javadoc/org/terrier/structures/LexiconEntry.html) object – which itself is an [EntryStatistics](http://terrier.org/docs/current/javadoc/org/terrier/structures/EntryStatistics.html) – and contains information including the statistics of that term:\n",
    "- `Nt` is the is the number of unique documents that each term occurs in (this is useful for calculating IDF)\n",
    "- `TF` is the total number of occurrences – some weighting models use this instead of Nt\n",
    "- The numbers in the `@{}` are pointers for Terrier to find that term in the inverted index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverted Index\n",
    "\n",
    "The inverted index tells us in which _documents_ each term occurs.\n",
    "\n",
    "The LexiconEntry is also the pointer to find the postings (i.e. occurrences) for that term in the inverted index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointer = index.getLexicon()[\"agenda\"]\n",
    "for posting in index.getInvertedIndex().getPostings(pointer):\n",
    "    print(f\"{posting.toString()} doclen={posting.getDocumentLength()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so we can see that `\"agenda\"` occurs once in documents with ids 520, 709 and 1052.\n",
    "\n",
    "Note that these are internal document ids of Terrier.\n",
    "We can know which documents (i.e. the string \"docno\" in the corpus DataFrame) from the metaindex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = index.getMetaIndex()\n",
    "pointer = index.getLexicon()[\"agenda\"]\n",
    "for posting in index.getInvertedIndex().getPostings(pointer):\n",
    "    docno = meta.getItem(\"docno\", posting.getId())\n",
    "    print(f\"{posting.toString()} doclen={posting.getDocumentLength()} docno={docno}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Pre-processing\n",
    "\n",
    "Looking at the terms in the Lexicon, do you think the index applied any text pre-processing?\n",
    "\n",
    "What happens if we lookup a very frequent term?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.getLexicon()[\"agenda\"].toString()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, Terrier removes standard stopwords and applies Porter's stemmer by default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index Variants\n",
    "\n",
    "We can modify the pre-processing transformations applied by Terrier when creating an index by changing its `term pipelines` property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No pre-processing\n",
    "indexer = pt.DFIndexer(\"./indexes/none\", overwrite=True)\n",
    "indexer.setProperty(\"termpipelines\", \"\")\n",
    "index_ref = indexer.index(docs_df[\"text\"], docs_df[\"docno\"])\n",
    "index = pt.IndexFactory.of(index_ref)\n",
    "print(index.getCollectionStatistics().toString())\n",
    "\n",
    "index.getLexicon()[\"the\"].toString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopwords removal\n",
    "indexer = pt.DFIndexer(\"./indexes/stopwords\", overwrite=True)\n",
    "indexer.setProperty(\"termpipelines\", \"Stopwords\")\n",
    "index_ref = indexer.index(docs_df[\"text\"], docs_df[\"docno\"])\n",
    "index = pt.IndexFactory.of(index_ref)\n",
    "print(index.getCollectionStatistics().toString())\n",
    "\n",
    "index.getLexicon()[\"agenda\"].toString()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the [org.terrier.terms](http://terrier.org/docs/current/javadoc/org/terrier/terms/package-summary.html) package for a list of the available term pipeline objects provided by Terrier.\n",
    "\n",
    "Similarly, tokenization is controlled by the _“tokeniser”_ property. For example:\n",
    "```python\n",
    "indexer.setProperty(\"tokeniser\", \"UTFTokeniser\")\n",
    "```\n",
    "\n",
    "[EnglishTokeniser](http://terrier.org/docs/current/javadoc/org/terrier/indexing/tokenisation/EnglishTokeniser.html) is the default tokeniser. Other tokenisers are listed in [org.terrier.indexing.tokenisation](http://terrier.org/docs/current/javadoc/org/terrier/indexing/tokenisation/package-summary.html) package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can also use the `blocks=True` argument for the index to store position information of every term in each document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = pt.DFIndexer(\"./indexes/default\", overwrite=True, blocks=True)\n",
    "index_ref = indexer.index(docs_df[\"text\"], docs_df[\"docno\"])\n",
    "index = pt.IndexFactory.of(index_ref)\n",
    "print(index.getCollectionStatistics().toString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading an Index\n",
    "\n",
    "Creating an index can take significant time for large document collections.\n",
    "We can load an index that we previously computed by specifying its path to `\"data/properties\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_ref = pt.IndexRef.of(\"./indexes/default/data.properties\")\n",
    "index = pt.IndexFactory.of(index_ref)\n",
    "print(index.getCollectionStatistics().toString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7: Searching an Index\n",
    "\n",
    "Now that we have an index, let's perform retrieval on it!\n",
    "\n",
    "In PyTerrier, search is done through the `BatchRetrieve()` method.\n",
    "BatchRetrieve takes two main arguments:\n",
    "- an index\n",
    "- a weighting model\n",
    "\n",
    "For instance, we can search for the word `\"wall\"` with our index and a term frequency (`Tf`) model by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = pt.BatchRetrieve(index, wmodel=\"Tf\")\n",
    "tf.search(\"wall\")  # NB. This can also be a multi-word expression (e.g. \"white wall\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `search()` method returns a DataFrame with columns:\n",
    " - `qid`: This is equal to \"1\" here since we only have a single query\n",
    " - `docid`: This is Terrier's internal integer for each document\n",
    " - `docno`: This is the external (string) unique identifier for each document\n",
    " - `rank`: This shows the descending order by score of retrieved documents\n",
    " - `score`: Since we use the `Tf` weighting model, this score corresponds the total frequency of the query (terms) in each document\n",
    " - `query`: The input query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also pass a DataFrame of one or more queries to the `transform()` method (rather than the `search()` method) with queries numbered \"q1\", \"q2\", etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = pd.DataFrame([[\"q1\", \"dragon\"], [\"q2\", \"wall\"]], columns=[\"qid\", \"query\"])\n",
    "tf.transform(queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, since `transform()` is the default method of a BatchRetrieve object `br`, we can directly write `br(queries)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf(queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, while we have used the simple `\"Tf\"` ranking function in the example above, Terrier supports many other models that can be used by simply changing the `wmodel=\"Tf\"` argument of `BatchRetrieve` (e.g. `wmodel=\"BM25\"` for BM25 scoring).\n",
    "A list of supported models is available in the [documentation](http://terrier.org/docs/current/javadoc/org/terrier/matching/models/package-summary.html).\n",
    "\n",
    "We can also tune internal Terrier configurations through the `properties` and `controls` arguments.\n",
    "For example, we can tune [BM25](http://terrier.org/docs/current/javadoc/org/terrier/matching/models/BM25.html)'s $b$, $k_1$ and $k_3$ parameters (c.f. Equation 4 [here](http://ir.dcs.gla.ac.uk/smooth/he-ecir05.pdf)) as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25 = pt.BatchRetrieve(index, wmodel=\"BM25\")  # default parameters\n",
    "bm25v2 = pt.BatchRetrieve(index, wmodel=\"BM25\", controls={\"c\": 0.1, \"bm25.k_1\": 2.0, \"bm25.k_3\": 10})\n",
    "bm25v3 = pt.BatchRetrieve(index, wmodel=\"BM25\", controls={\"c\": 8, \"bm25.k_1\": 1.4, \"bm25.k_3\": 10})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the $b$ parameters is set via the generic `\"c\"` control parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8: Measuring Retrieval Performance\n",
    "\n",
    "Ranking metrics allow us to decide which search engine models are better than others for our application.\n",
    "\n",
    "While we will look into evaluation metrics in a future lab, we can use PyTerrier's `Experiment` abstraction to evaluate multiple (BatchRetrieve) systems on queries \"Q\" and labels \"RA\":\n",
    "```python\n",
    "pt.Experiment([br1, br2], Q, RA, eval_metrics=[\"map\", \"ndcg\"])\n",
    "```\n",
    "\n",
    "For instance, we can evaluate the MAP and NDCG metrics of the models we defined so far on the first three topics of our collection as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qrels_df = qrels_df.astype({'label': 'int32'})\n",
    "pt.Experiment(\n",
    "    retr_systems=[tf, bm25, bm25v2, bm25v3],\n",
    "    names=['TF', 'BM25', 'BM25 (0.1, 2.0, 10)', 'BM25 (8, 1.4, 10)'],\n",
    "    topics=topics_df[:3],\n",
    "    qrels=qrels_df,\n",
    "    eval_metrics=[\"map\", \"ndcg\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d8ed0073c41b023cdd22b6268c6b3f0c9b6d97a6234cf243afa672a36c79f6c6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
